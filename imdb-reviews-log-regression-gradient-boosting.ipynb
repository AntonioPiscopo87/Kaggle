{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Let's do some basics import and CountVectorizer so to call the transform() function on one or more documents as needed to encode each as a vector\nfrom os import path\nfrom pandas import DataFrame\nfrom sklearn.feature_extraction import text\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport re","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's import some NLP modules such as PorterStemmer, SnowballStemmer, WordNetLemmetizer\n# download vader_lexicon, and stopwords\n\nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem import LancasterStemmer\nfrom nltk.stem import WordNetLemmatizer    # Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meaning to one word.\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize\nnltk.download('vader_lexicon')\nnltk.download('stopwords')\nnltk.download('wordnet')","execution_count":3,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n  warnings.warn(\"The twython library has not been installed. \"\n","name":"stderr"},{"output_type":"stream","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","name":"stdout"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's import some visualization modules\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import style\nimport matplotlib.colors","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import wordcloud   # Sentiment-based Word Clouds\nfrom wordcloud import WordCloud, STOPWORDS \nfrom PIL import Image","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change and set directory to kaggle/input\n\nos.chdir('/kaggle/input')\nos.getcwd()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"'/kaggle/input'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's read IMDB Dataset and store it into a dataframe \"df\"\n\ndf=pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv',header=0,error_bad_lines=True,encoding='utf8')\n\ndf.dtypes","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"review       object\nsentiment    object\ndtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's look at our table\ndf.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's define a function \"sc\" to run sentimental analysis on the text \"review\" and return the compound value (-1 to +1)\ndef sc(x):\n    score=SentimentIntensityAnalyzer().polarity_scores(x)\n    return score['compound']","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Let's apply the compound score of our sentimental analysis to \"review\" storing the results in a new column \"SentScore\" through \n# map function\n\ndf[\"SentScore\"]=df[\"review\"].map(sc)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's look at our updated table \ndf.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"                                              review sentiment  SentScore\n0  One of the other reviewers has mentioned that ...  positive    -0.9951\n1  A wonderful little production. <br /><br />The...  positive     0.9641\n2  I thought this was a wonderful way to spend ti...  positive     0.9605\n3  Basically there's a family where a little boy ...  negative    -0.9213\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive     0.9744","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>SentScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>-0.9951</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>0.9641</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>0.9605</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>-0.9213</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>0.9744</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's define a function \"sc\" to run sentimental analysis on the text \"review\" and return the compound value (-1 to +1)\n\n\ndef sca(lb):\n    if lb >= .6:\n        return \"Very Good\"\n    elif (lb > .2) and (lb < .6):\n        return \"Good\"\n    elif (lb > -.2) and (lb < .2):\n        return \"Average\"\n    elif (lb > -.6) and (lb < -.2):\n        return \"Disappointing\"\n     \n    else:\n        return \"Regrettable\"","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we insert a column to indicate the class of the review (\"Very Good\" , \"Good\", \"Average\", \"Disappointing\", \"Regrettable\")\n\ndf[\"SentClass\"]=df[\"SentScore\"].map(sca)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check our updated table\n\ndf.head(15)","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"                                               review sentiment  SentScore  \\\n0   One of the other reviewers has mentioned that ...  positive    -0.9951   \n1   A wonderful little production. <br /><br />The...  positive     0.9641   \n2   I thought this was a wonderful way to spend ti...  positive     0.9605   \n3   Basically there's a family where a little boy ...  negative    -0.9213   \n4   Petter Mattei's \"Love in the Time of Money\" is...  positive     0.9744   \n5   Probably my all-time favorite movie, a story o...  positive     0.9828   \n6   I sure would like to see a resurrection of a u...  positive     0.9022   \n7   This show was an amazing, fresh & innovative i...  negative     0.8596   \n8   Encouraged by the positive comments about this...  negative     0.2362   \n9   If you like original gut wrenching laughter yo...  positive     0.9149   \n10  Phil the Alien is one of those quirky films wh...  negative     0.9482   \n11  I saw this movie when I was about 12 when it c...  negative     0.5223   \n12  So im not a big fan of Boll's work but then ag...  negative    -0.9721   \n13  The cast played Shakespeare.<br /><br />Shakes...  negative     0.3425   \n14  This a fantastic movie of three prisoners who ...  positive     0.6168   \n\n      SentClass  \n0   Regrettable  \n1     Very Good  \n2     Very Good  \n3   Regrettable  \n4     Very Good  \n5     Very Good  \n6     Very Good  \n7     Very Good  \n8          Good  \n9     Very Good  \n10    Very Good  \n11         Good  \n12  Regrettable  \n13         Good  \n14    Very Good  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>SentScore</th>\n      <th>SentClass</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>-0.9951</td>\n      <td>Regrettable</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>0.9641</td>\n      <td>Very Good</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>0.9605</td>\n      <td>Very Good</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>-0.9213</td>\n      <td>Regrettable</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>0.9744</td>\n      <td>Very Good</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Probably my all-time favorite movie, a story o...</td>\n      <td>positive</td>\n      <td>0.9828</td>\n      <td>Very Good</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>I sure would like to see a resurrection of a u...</td>\n      <td>positive</td>\n      <td>0.9022</td>\n      <td>Very Good</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>This show was an amazing, fresh &amp; innovative i...</td>\n      <td>negative</td>\n      <td>0.8596</td>\n      <td>Very Good</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Encouraged by the positive comments about this...</td>\n      <td>negative</td>\n      <td>0.2362</td>\n      <td>Good</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>If you like original gut wrenching laughter yo...</td>\n      <td>positive</td>\n      <td>0.9149</td>\n      <td>Very Good</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Phil the Alien is one of those quirky films wh...</td>\n      <td>negative</td>\n      <td>0.9482</td>\n      <td>Very Good</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>I saw this movie when I was about 12 when it c...</td>\n      <td>negative</td>\n      <td>0.5223</td>\n      <td>Good</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>So im not a big fan of Boll's work but then ag...</td>\n      <td>negative</td>\n      <td>-0.9721</td>\n      <td>Regrettable</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n      <td>negative</td>\n      <td>0.3425</td>\n      <td>Good</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>This a fantastic movie of three prisoners who ...</td>\n      <td>positive</td>\n      <td>0.6168</td>\n      <td>Very Good</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We define a function for which relatively to the \"sentiment\" column, positive=1 | negative=0\n\ndef num(lb):\n    if lb == 'positive':\n        return 1   \n    else:\n        return 0","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's create a new column \"sentiment_bin\" applying the function above using .map\n\ndf[\"sentiment_bin\"]=df[\"sentiment\"].map(num)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the updated table\n\ndf.head(15)","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"                                               review sentiment  SentScore  \\\n0   One of the other reviewers has mentioned that ...  positive    -0.9951   \n1   A wonderful little production. <br /><br />The...  positive     0.9641   \n2   I thought this was a wonderful way to spend ti...  positive     0.9605   \n3   Basically there's a family where a little boy ...  negative    -0.9213   \n4   Petter Mattei's \"Love in the Time of Money\" is...  positive     0.9744   \n5   Probably my all-time favorite movie, a story o...  positive     0.9828   \n6   I sure would like to see a resurrection of a u...  positive     0.9022   \n7   This show was an amazing, fresh & innovative i...  negative     0.8596   \n8   Encouraged by the positive comments about this...  negative     0.2362   \n9   If you like original gut wrenching laughter yo...  positive     0.9149   \n10  Phil the Alien is one of those quirky films wh...  negative     0.9482   \n11  I saw this movie when I was about 12 when it c...  negative     0.5223   \n12  So im not a big fan of Boll's work but then ag...  negative    -0.9721   \n13  The cast played Shakespeare.<br /><br />Shakes...  negative     0.3425   \n14  This a fantastic movie of three prisoners who ...  positive     0.6168   \n\n      SentClass  sentiment_bin  \n0   Regrettable              1  \n1     Very Good              1  \n2     Very Good              1  \n3   Regrettable              0  \n4     Very Good              1  \n5     Very Good              1  \n6     Very Good              1  \n7     Very Good              0  \n8          Good              0  \n9     Very Good              1  \n10    Very Good              0  \n11         Good              0  \n12  Regrettable              0  \n13         Good              0  \n14    Very Good              1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>SentScore</th>\n      <th>SentClass</th>\n      <th>sentiment_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>-0.9951</td>\n      <td>Regrettable</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>0.9641</td>\n      <td>Very Good</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>0.9605</td>\n      <td>Very Good</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>-0.9213</td>\n      <td>Regrettable</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>0.9744</td>\n      <td>Very Good</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Probably my all-time favorite movie, a story o...</td>\n      <td>positive</td>\n      <td>0.9828</td>\n      <td>Very Good</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>I sure would like to see a resurrection of a u...</td>\n      <td>positive</td>\n      <td>0.9022</td>\n      <td>Very Good</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>This show was an amazing, fresh &amp; innovative i...</td>\n      <td>negative</td>\n      <td>0.8596</td>\n      <td>Very Good</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Encouraged by the positive comments about this...</td>\n      <td>negative</td>\n      <td>0.2362</td>\n      <td>Good</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>If you like original gut wrenching laughter yo...</td>\n      <td>positive</td>\n      <td>0.9149</td>\n      <td>Very Good</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Phil the Alien is one of those quirky films wh...</td>\n      <td>negative</td>\n      <td>0.9482</td>\n      <td>Very Good</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>I saw this movie when I was about 12 when it c...</td>\n      <td>negative</td>\n      <td>0.5223</td>\n      <td>Good</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>So im not a big fan of Boll's work but then ag...</td>\n      <td>negative</td>\n      <td>-0.9721</td>\n      <td>Regrettable</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n      <td>negative</td>\n      <td>0.3425</td>\n      <td>Good</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>This a fantastic movie of three prisoners who ...</td>\n      <td>positive</td>\n      <td>0.6168</td>\n      <td>Very Good</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Similarly to what we did above, for the SentScore results (-1 to +1) we define a function for which a value >= 0 equals 1(positive), else 0(negative)\n\ndef numscore(lb):\n    if lb >= 0:\n        return 1     \n    else:\n        return 0","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's create a new column \"SentScore_bin\" applying the function above using .map\n\ndf[\"SentScore_bin\"]=df[\"SentScore\"].map(numscore)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the updated table\n\ndf.head(15)","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"                                               review sentiment  SentScore  \\\n0   One of the other reviewers has mentioned that ...  positive    -0.9951   \n1   A wonderful little production. <br /><br />The...  positive     0.9641   \n2   I thought this was a wonderful way to spend ti...  positive     0.9605   \n3   Basically there's a family where a little boy ...  negative    -0.9213   \n4   Petter Mattei's \"Love in the Time of Money\" is...  positive     0.9744   \n5   Probably my all-time favorite movie, a story o...  positive     0.9828   \n6   I sure would like to see a resurrection of a u...  positive     0.9022   \n7   This show was an amazing, fresh & innovative i...  negative     0.8596   \n8   Encouraged by the positive comments about this...  negative     0.2362   \n9   If you like original gut wrenching laughter yo...  positive     0.9149   \n10  Phil the Alien is one of those quirky films wh...  negative     0.9482   \n11  I saw this movie when I was about 12 when it c...  negative     0.5223   \n12  So im not a big fan of Boll's work but then ag...  negative    -0.9721   \n13  The cast played Shakespeare.<br /><br />Shakes...  negative     0.3425   \n14  This a fantastic movie of three prisoners who ...  positive     0.6168   \n\n      SentClass  sentiment_bin  SentScore_bin  \n0   Regrettable              1              0  \n1     Very Good              1              1  \n2     Very Good              1              1  \n3   Regrettable              0              0  \n4     Very Good              1              1  \n5     Very Good              1              1  \n6     Very Good              1              1  \n7     Very Good              0              1  \n8          Good              0              1  \n9     Very Good              1              1  \n10    Very Good              0              1  \n11         Good              0              1  \n12  Regrettable              0              0  \n13         Good              0              1  \n14    Very Good              1              1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>SentScore</th>\n      <th>SentClass</th>\n      <th>sentiment_bin</th>\n      <th>SentScore_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>-0.9951</td>\n      <td>Regrettable</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>0.9641</td>\n      <td>Very Good</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>0.9605</td>\n      <td>Very Good</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>-0.9213</td>\n      <td>Regrettable</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>0.9744</td>\n      <td>Very Good</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Probably my all-time favorite movie, a story o...</td>\n      <td>positive</td>\n      <td>0.9828</td>\n      <td>Very Good</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>I sure would like to see a resurrection of a u...</td>\n      <td>positive</td>\n      <td>0.9022</td>\n      <td>Very Good</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>This show was an amazing, fresh &amp; innovative i...</td>\n      <td>negative</td>\n      <td>0.8596</td>\n      <td>Very Good</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Encouraged by the positive comments about this...</td>\n      <td>negative</td>\n      <td>0.2362</td>\n      <td>Good</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>If you like original gut wrenching laughter yo...</td>\n      <td>positive</td>\n      <td>0.9149</td>\n      <td>Very Good</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Phil the Alien is one of those quirky films wh...</td>\n      <td>negative</td>\n      <td>0.9482</td>\n      <td>Very Good</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>I saw this movie when I was about 12 when it c...</td>\n      <td>negative</td>\n      <td>0.5223</td>\n      <td>Good</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>So im not a big fan of Boll's work but then ag...</td>\n      <td>negative</td>\n      <td>-0.9721</td>\n      <td>Regrettable</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n      <td>negative</td>\n      <td>0.3425</td>\n      <td>Good</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>This a fantastic movie of three prisoners who ...</td>\n      <td>positive</td>\n      <td>0.6168</td>\n      <td>Very Good</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's do now some TEXT ADJUSTMENTS / CLEANING","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make text lower case\ndf[\"review\"]  = df[\"review\"].str.lower()","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove digits from text\ndef Remove_digit(text):\n    result = re.sub(r\"\\d\", \"\", text)\n    return result","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove HTML from text\ndef remove_html(text):\n    result = re.sub(r'<.*?>','',text) # Find out anything that is in between < & > symbol \n    return result","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove special text characters\ndef remove_spl(text):\n    result = re.sub(r'\\W',' ',text) \n    return result","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Link words with similar meaning to one word (in context)\ndef lem_word(text):\n    result= WordNetLemmatizer().lemmatize(text)\n    return result","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's apply all of the above functions to the text column \"review\"\n\ndf[\"review\"]  = df[\"review\"].apply(Remove_digit)\ndf[\"review\"]  = df[\"review\"].apply(remove_html)\ndf[\"review\"]  = df[\"review\"].apply(remove_spl)\ndf[\"review\"]  = df[\"review\"].apply(lem_word)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the updated table\n\ndf.head()","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"                                              review sentiment  SentScore  \\\n0  one of the other reviewers has mentioned that ...  positive    -0.9951   \n1  a wonderful little production  the filming tec...  positive     0.9641   \n2  i thought this was a wonderful way to spend ti...  positive     0.9605   \n3  basically there s a family where a little boy ...  negative    -0.9213   \n4  petter mattei s  love in the time of money  is...  positive     0.9744   \n\n     SentClass  sentiment_bin  SentScore_bin  \n0  Regrettable              1              0  \n1    Very Good              1              1  \n2    Very Good              1              1  \n3  Regrettable              0              0  \n4    Very Good              1              1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>SentScore</th>\n      <th>SentClass</th>\n      <th>sentiment_bin</th>\n      <th>SentScore_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>-0.9951</td>\n      <td>Regrettable</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a wonderful little production  the filming tec...</td>\n      <td>positive</td>\n      <td>0.9641</td>\n      <td>Very Good</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>0.9605</td>\n      <td>Very Good</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically there s a family where a little boy ...</td>\n      <td>negative</td>\n      <td>-0.9213</td>\n      <td>Regrettable</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter mattei s  love in the time of money  is...</td>\n      <td>positive</td>\n      <td>0.9744</td>\n      <td>Very Good</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's store the adjusted text to the object 'corpus1' and transform it into a List\ncorpus1=df['review'].tolist()","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create an object \"corpus\" that includes the first 1000 values of the list 'corpus1', otherwise the machine could take too long to run the command\n\ncorpus=corpus1[ :1000]","execution_count":89,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count Vectorisation\n# I have defined ngram range to be unigrams and bigrams (it starts with one word and goes up to two when vectorizing)\n\nfrom sklearn.feature_extraction import text\n\ncv = text.CountVectorizer(input=corpus,ngram_range=(1,2),stop_words='english')\nmatrix = cv.fit_transform(corpus)\n\n# I am converting the matrix_cv into a dataframe \ncorpus2 = pd.DataFrame(matrix.toarray(), columns=cv.get_feature_names())","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's take a snapshot at the data\ncorpus2.head()","execution_count":78,"outputs":[{"output_type":"execute_result","execution_count":78,"data":{"text/plain":"   _fargo_  _fargo_ just  _inspire_  _inspire_ audience  aaargh  aaargh wes  \\\n0        0             0          0                   0       0           0   \n1        0             0          0                   0       0           0   \n2        0             0          0                   0       0           0   \n3        0             0          0                   0       0           0   \n4        0             0          0                   0       0           0   \n\n   aaliyah  aaliyah soul  aamir  aamir khan  ...  zulu  zulu simply  zwick  \\\n0        0             0      0           0  ...     0            0      0   \n1        0             0      0           0  ...     0            0      0   \n2        0             0      0           0  ...     0            0      0   \n3        0             0      0           0  ...     0            0      0   \n4        0             0      0           0  ...     0            0      0   \n\n   zwick shame  zzzzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzzz imdb  élan  \\\n0            0                   0                        0     0   \n1            0                   0                        0     0   \n2            0                   0                        0     0   \n3            0                   0                        0     0   \n4            0                   0                        0     0   \n\n   élan unique  ísnt  ísnt entertaining  \n0            0     0                  0  \n1            0     0                  0  \n2            0     0                  0  \n3            0     0                  0  \n4            0     0                  0  \n\n[5 rows x 110012 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_fargo_</th>\n      <th>_fargo_ just</th>\n      <th>_inspire_</th>\n      <th>_inspire_ audience</th>\n      <th>aaargh</th>\n      <th>aaargh wes</th>\n      <th>aaliyah</th>\n      <th>aaliyah soul</th>\n      <th>aamir</th>\n      <th>aamir khan</th>\n      <th>...</th>\n      <th>zulu</th>\n      <th>zulu simply</th>\n      <th>zwick</th>\n      <th>zwick shame</th>\n      <th>zzzzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzzz imdb</th>\n      <th>élan</th>\n      <th>élan unique</th>\n      <th>ísnt</th>\n      <th>ísnt entertaining</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 110012 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One thing to notice here is the dimension of this data\n# We have 1000 documents (rows) which is consistent with the selected amount of rows of our list corpus \n# and 110012 columns which is humangous. We have a created a giant matrix\n\n# It is noticeable that many features contain 0, since not all words willbe present across documents of the corpus(2)\n\ncorpus2.shape","execution_count":79,"outputs":[{"output_type":"execute_result","execution_count":79,"data":{"text/plain":"(1000, 110012)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TF-IDF, Term Frequency and Inverse Document Freq\n# We run a TF-IDF representation on the same corpus, same like before and also this time removing the english stop_words\n\n\ntf = text.TfidfVectorizer(input=corpus, ngram_range=(1,2),stop_words='english')\n\nmatrix1 = tf.fit_transform(corpus)\n\n# I am converting the matrix1 into a dataframe X\nX = pd.DataFrame(matrix1.toarray(), columns=tf.get_feature_names())","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's take a look at our matrix X\n\nX.head()","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"   _fargo_  _fargo_ just  _inspire_  _inspire_ audience  aaargh  aaargh wes  \\\n0      0.0           0.0        0.0                 0.0     0.0         0.0   \n1      0.0           0.0        0.0                 0.0     0.0         0.0   \n2      0.0           0.0        0.0                 0.0     0.0         0.0   \n3      0.0           0.0        0.0                 0.0     0.0         0.0   \n4      0.0           0.0        0.0                 0.0     0.0         0.0   \n\n   aaliyah  aaliyah soul  aamir  aamir khan  ...  zulu  zulu simply  zwick  \\\n0      0.0           0.0    0.0         0.0  ...   0.0          0.0    0.0   \n1      0.0           0.0    0.0         0.0  ...   0.0          0.0    0.0   \n2      0.0           0.0    0.0         0.0  ...   0.0          0.0    0.0   \n3      0.0           0.0    0.0         0.0  ...   0.0          0.0    0.0   \n4      0.0           0.0    0.0         0.0  ...   0.0          0.0    0.0   \n\n   zwick shame  zzzzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzzz imdb  élan  \\\n0          0.0                 0.0                      0.0   0.0   \n1          0.0                 0.0                      0.0   0.0   \n2          0.0                 0.0                      0.0   0.0   \n3          0.0                 0.0                      0.0   0.0   \n4          0.0                 0.0                      0.0   0.0   \n\n   élan unique  ísnt  ísnt entertaining  \n0          0.0   0.0                0.0  \n1          0.0   0.0                0.0  \n2          0.0   0.0                0.0  \n3          0.0   0.0                0.0  \n4          0.0   0.0                0.0  \n\n[5 rows x 110012 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_fargo_</th>\n      <th>_fargo_ just</th>\n      <th>_inspire_</th>\n      <th>_inspire_ audience</th>\n      <th>aaargh</th>\n      <th>aaargh wes</th>\n      <th>aaliyah</th>\n      <th>aaliyah soul</th>\n      <th>aamir</th>\n      <th>aamir khan</th>\n      <th>...</th>\n      <th>zulu</th>\n      <th>zulu simply</th>\n      <th>zwick</th>\n      <th>zwick shame</th>\n      <th>zzzzzzzzzzzzzzzzzz</th>\n      <th>zzzzzzzzzzzzzzzzzz imdb</th>\n      <th>élan</th>\n      <th>élan unique</th>\n      <th>ísnt</th>\n      <th>ísnt entertaining</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 110012 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's set our y to be the first 1000 values of the column SentScore_bin (based on our sentiment analysis)\n\ny = df['SentScore_bin'][:1000].values","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's take a look at the array 'y'\nprint(y)","execution_count":35,"outputs":[{"output_type":"stream","text":"[0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0\n 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1\n 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1 0\n 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1\n 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1\n 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1\n 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1\n 1 1 1 0 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 0\n 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1\n 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1\n 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0\n 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0\n 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1\n 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0\n 1 1 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 0\n 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0\n 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1\n 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1\n 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1\n 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0\n 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0\n 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1\n 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1\n 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 1\n 1]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are going to try and run the RandomForest Classifier on X= vectorized matrix and y= SentScore_bin\n# using the fit transformation of the tf - idf matrix to array =X\n\n# Let's split X and y in training and testing data\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=23)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's set the RandomForestClassifier and set the parameters\n# Let's fit the model on X and y training data\n\nfrom sklearn.ensemble import RandomForestClassifier\ntext_classifier=RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_features=0.3, min_samples_leaf=4, min_samples_split=9, n_estimators=100)\ntext_classifier.fit(X_train, y_train)","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features=0.3,\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=4, min_samples_split=9,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's run the prediction on the X test data and store them into the object 'predictions'\n\npredictions = text_classifier.predict(X_test)","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can see that running the RANDOM FOREST CLASSIFIER we get an accuracy score of 68%. NOT amazing!\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n \nprint(confusion_matrix(y_test,predictions))  \nprint(classification_report(y_test,predictions))  \nprint(accuracy_score(y_test, predictions))","execution_count":39,"outputs":[{"output_type":"stream","text":"[[ 32  45]\n [ 19 104]]\n              precision    recall  f1-score   support\n\n           0       0.63      0.42      0.50        77\n           1       0.70      0.85      0.76       123\n\n    accuracy                           0.68       200\n   macro avg       0.66      0.63      0.63       200\nweighted avg       0.67      0.68      0.66       200\n\n0.68\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try LOGISTIC REGRESSION","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training the model\nlr=LogisticRegression(C=1.0,class_weight=None,dual=False,fit_intercept=True,intercept_scaling=1,l1_ratio=None,max_iter=100,\nmulti_class='auto',n_jobs=None,penalty='l2',random_state=23,solver='lbfgs',tol=0.0001,verbose=0,warm_start=False)\n#Fitting the model for tfidf features\nlr_tfidf=lr.fit(X_train,y_train)\nprint(lr_tfidf)","execution_count":41,"outputs":[{"output_type":"stream","text":"LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=23, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Predicting the model for tfidf features\nlr_tfidf_predict=lr.predict(X_test)\nprint(lr_tfidf_predict)","execution_count":42,"outputs":[{"output_type":"stream","text":"[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy score running a LOGISTIC REGRESSION is pretty low.....only 61.5%!\n\n#Accuracy score for tfidf features\nlr_tfidf_score=accuracy_score(y_test,lr_tfidf_predict)\nprint(\"lr_tfidf_score :\",lr_tfidf_score)","execution_count":43,"outputs":[{"output_type":"stream","text":"lr_tfidf_score : 0.615\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification report for tfidf features\nlr_tfidf_report=classification_report(y_test,lr_tfidf_predict,target_names=['0','1'])\nprint(lr_tfidf_report)","execution_count":44,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        77\n           1       0.61      1.00      0.76       123\n\n    accuracy                           0.61       200\n   macro avg       0.31      0.50      0.38       200\nweighted avg       0.38      0.61      0.47       200\n\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GRADIENT BOOSTING CLASSIFIER","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=GradientBoostingClassifier(n_estimators=80,random_state=23)","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train,y_train)","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n                           learning_rate=0.1, loss='deviance', max_depth=3,\n                           max_features=None, max_leaf_nodes=None,\n                           min_impurity_decrease=0.0, min_impurity_split=None,\n                           min_samples_leaf=1, min_samples_split=2,\n                           min_weight_fraction_leaf=0.0, n_estimators=80,\n                           n_iter_no_change=None, presort='deprecated',\n                           random_state=23, subsample=1.0, tol=0.0001,\n                           validation_fraction=0.1, verbose=0,\n                           warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_test,y_test)","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"0.725"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nmod=GridSearchCV(clf,param_grid={'n_estimators': [80,100,120,140,160]})","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod.fit(X_train,y_train)","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"GridSearchCV(cv=None, error_score=nan,\n             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n                                                  criterion='friedman_mse',\n                                                  init=None, learning_rate=0.1,\n                                                  loss='deviance', max_depth=3,\n                                                  max_features=None,\n                                                  max_leaf_nodes=None,\n                                                  min_impurity_decrease=0.0,\n                                                  min_impurity_split=None,\n                                                  min_samples_leaf=1,\n                                                  min_samples_split=2,\n                                                  min_weight_fraction_leaf=0.0,\n                                                  n_estimators=80,\n                                                  n_iter_no_change=None,\n                                                  presort='deprecated',\n                                                  random_state=23,\n                                                  subsample=1.0, tol=0.0001,\n                                                  validation_fraction=0.1,\n                                                  verbose=0, warm_start=False),\n             iid='deprecated', n_jobs=None, param_grid={'n_estimators': [80]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod.best_estimator_","execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n                           learning_rate=0.1, loss='deviance', max_depth=3,\n                           max_features=None, max_leaf_nodes=None,\n                           min_impurity_decrease=0.0, min_impurity_split=None,\n                           min_samples_leaf=1, min_samples_split=2,\n                           min_weight_fraction_leaf=0.0, n_estimators=80,\n                           n_iter_no_change=None, presort='deprecated',\n                           random_state=23, subsample=1.0, tol=0.0001,\n                           validation_fraction=0.1, verbose=0,\n                           warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=GradientBoostingClassifier(n_estimators=100,random_state=23)\nclf.fit(X_train,y_train)","execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n                           learning_rate=0.1, loss='deviance', max_depth=3,\n                           max_features=None, max_leaf_nodes=None,\n                           min_impurity_decrease=0.0, min_impurity_split=None,\n                           min_samples_leaf=1, min_samples_split=2,\n                           min_weight_fraction_leaf=0.0, n_estimators=100,\n                           n_iter_no_change=None, presort='deprecated',\n                           random_state=23, subsample=1.0, tol=0.0001,\n                           validation_fraction=0.1, verbose=0,\n                           warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_test,y_test)","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"0.715"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.feature_importances_","execution_count":54,"outputs":[{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"array([0., 0., 0., ..., 0., 0., 0.])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_imp=pd.Series(clf.feature_importances_)\nfeature_imp.sort_values(ascending=False)","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"6343      0.067244\n41101     0.061226\n108616    0.056553\n8108      0.043326\n65082     0.035758\n            ...   \n73273     0.000000\n73274     0.000000\n73275     0.000000\n73276     0.000000\n0         0.000000\nLength: 110012, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's now repeat the operations setting the first 1000 values of our column 'sentiment_bin' as our \"y\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['sentiment_bin'][:1000].values","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We split again in training and test data\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=23)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForestClassifier\n\nfrom sklearn.ensemble import RandomForestClassifier\ntext_classifier=RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_features=0.3, min_samples_leaf=4, min_samples_split=9, n_estimators=100)\ntext_classifier.fit(X_train, y_train)","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features=0.3,\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=4, min_samples_split=9,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = text_classifier.predict(X_test)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It seems to be more accurate with a score of 78%!\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n \nprint(confusion_matrix(y_test,predictions))  \nprint(classification_report(y_test,predictions))  \nprint(accuracy_score(y_test, predictions))","execution_count":61,"outputs":[{"output_type":"stream","text":"[[76 27]\n [18 79]]\n              precision    recall  f1-score   support\n\n           0       0.81      0.74      0.77       103\n           1       0.75      0.81      0.78        97\n\n    accuracy                           0.78       200\n   macro avg       0.78      0.78      0.77       200\nweighted avg       0.78      0.78      0.77       200\n\n0.775\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try again LOGISTIC REGRESSION\n\nfrom sklearn.linear_model import LogisticRegression\n#training the model\nlr=LogisticRegression(C=1.0,class_weight=None,dual=False,fit_intercept=True,intercept_scaling=1,l1_ratio=None,max_iter=100,\nmulti_class='auto',n_jobs=None,penalty='l2',random_state=23,solver='lbfgs',tol=0.0001,verbose=0,warm_start=False)\n#Fitting the model for tfidf features\nlr_tfidf=lr.fit(X_train,y_train)\nprint(lr_tfidf)","execution_count":62,"outputs":[{"output_type":"stream","text":"LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=23, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Predicting the model for tfidf features\nlr_tfidf_predict=lr.predict(X_test)\nprint(lr_tfidf_predict)","execution_count":63,"outputs":[{"output_type":"stream","text":"[0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1\n 0 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0\n 1 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0\n 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1\n 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0\n 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic regression with y=sentiment_bin gives us the highest accuracy----81%! Not bad\n\n#Accuracy score for tfidf features\nlr_tfidf_score=accuracy_score(y_test,lr_tfidf_predict)\nprint(\"lr_tfidf_score :\",lr_tfidf_score)","execution_count":64,"outputs":[{"output_type":"stream","text":"lr_tfidf_score : 0.805\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification report for tfidf features\nlr_tfidf_report=classification_report(y_test,lr_tfidf_predict,target_names=['0','1'])\nprint(lr_tfidf_report)","execution_count":65,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.87      0.73      0.79       103\n           1       0.75      0.89      0.82        97\n\n    accuracy                           0.81       200\n   macro avg       0.81      0.81      0.80       200\nweighted avg       0.82      0.81      0.80       200\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try with the GRADIENT BOOSTING CLASSIFIER\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nclf=GradientBoostingClassifier(n_estimators=80,random_state=23)\nclf.fit(X_train,y_train)","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n                           learning_rate=0.1, loss='deviance', max_depth=3,\n                           max_features=None, max_leaf_nodes=None,\n                           min_impurity_decrease=0.0, min_impurity_split=None,\n                           min_samples_leaf=1, min_samples_split=2,\n                           min_weight_fraction_leaf=0.0, n_estimators=80,\n                           n_iter_no_change=None, presort='deprecated',\n                           random_state=23, subsample=1.0, tol=0.0001,\n                           validation_fraction=0.1, verbose=0,\n                           warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_test,y_test)","execution_count":70,"outputs":[{"output_type":"execute_result","execution_count":70,"data":{"text/plain":"0.77"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nmod=GridSearchCV(clf,param_grid={'n_estimators': [80,100]})","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod.fit(X_train,y_train)","execution_count":73,"outputs":[{"output_type":"execute_result","execution_count":73,"data":{"text/plain":"GridSearchCV(cv=None, error_score=nan,\n             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n                                                  criterion='friedman_mse',\n                                                  init=None, learning_rate=0.1,\n                                                  loss='deviance', max_depth=3,\n                                                  max_features=None,\n                                                  max_leaf_nodes=None,\n                                                  min_impurity_decrease=0.0,\n                                                  min_impurity_split=None,\n                                                  min_samples_leaf=1,\n                                                  min_samples_split=2,\n                                                  min_weight_fraction_leaf=0.0,\n                                                  n_estimators=80,\n                                                  n_iter_no_change=None,\n                                                  presort='deprecated',\n                                                  random_state=23,\n                                                  subsample=1.0, tol=0.0001,\n                                                  validation_fraction=0.1,\n                                                  verbose=0, warm_start=False),\n             iid='deprecated', n_jobs=None,\n             param_grid={'n_estimators': [80, 100]}, pre_dispatch='2*n_jobs',\n             refit=True, return_train_score=False, scoring=None, verbose=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod.best_estimator_","execution_count":74,"outputs":[{"output_type":"execute_result","execution_count":74,"data":{"text/plain":"GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n                           learning_rate=0.1, loss='deviance', max_depth=3,\n                           max_features=None, max_leaf_nodes=None,\n                           min_impurity_decrease=0.0, min_impurity_split=None,\n                           min_samples_leaf=1, min_samples_split=2,\n                           min_weight_fraction_leaf=0.0, n_estimators=100,\n                           n_iter_no_change=None, presort='deprecated',\n                           random_state=23, subsample=1.0, tol=0.0001,\n                           validation_fraction=0.1, verbose=0,\n                           warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n                           learning_rate=0.1, loss='deviance', max_depth=3,\n                           max_features=None, max_leaf_nodes=None,\n                           min_impurity_decrease=0.0, min_impurity_split=None,\n                           min_samples_leaf=1, min_samples_split=2,\n                           min_weight_fraction_leaf=0.0, n_estimators=100,\n                           n_iter_no_change=None, presort='deprecated',\n                           random_state=23, subsample=1.0, tol=0.0001,\n                           validation_fraction=0.1, verbose=0,\n                           warm_start=False)\nclf.fit(X_train,y_train)","execution_count":76,"outputs":[{"output_type":"execute_result","execution_count":76,"data":{"text/plain":"GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n                           learning_rate=0.1, loss='deviance', max_depth=3,\n                           max_features=None, max_leaf_nodes=None,\n                           min_impurity_decrease=0.0, min_impurity_split=None,\n                           min_samples_leaf=1, min_samples_split=2,\n                           min_weight_fraction_leaf=0.0, n_estimators=100,\n                           n_iter_no_change=None, presort='deprecated',\n                           random_state=23, subsample=1.0, tol=0.0001,\n                           validation_fraction=0.1, verbose=0,\n                           warm_start=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_test,y_test)","execution_count":77,"outputs":[{"output_type":"execute_result","execution_count":77,"data":{"text/plain":"0.765"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}